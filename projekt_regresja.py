# -*- coding: utf-8 -*-
"""Projekt_regresja.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S-FDZnl9KeDqHTUT3-gRcYRnGFCut2ne

#Zaimportowanie bibliotek
"""

import regex as re
# zaimportowanie pandas
import pandas as pd
# zaimportowanie pakietów do wizualizacji danych 
import matplotlib.pyplot as plt
import numpy as np
# zaimportowanie funkcji do modelowania predykcyjnego
from sklearn.model_selection import train_test_split 
from sklearn import tree
from sklearn.metrics import r2_score
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_percentage_error
import seaborn as sns

"""#Zapoznanie ze zbiorem danych"""

# wgranie zbioru danych laptop_price.csv
laptop=pd.read_csv('laptop_price.csv', encoding='latin-1')

laptop.head()

laptop.info()

laptop.describe()

"""#Przetwarzanie i wizualizacja danych"""

laptop.isna().sum()

laptop['Weight']=laptop['Weight'].replace('kg', '', regex=True)

laptop['Ram']=laptop['Ram'].replace('GB', '', regex=True)

set(laptop['Ram'])

set(laptop['Memory'])

set(laptop['Cpu'])

text = laptop['Cpu']

pattern = '[+-]?([0-9]+[.][0-9]*)GHz$'

Cpu_values=text.str.findall(pattern)
Cpu_values

laptop['Cpu_values']=Cpu_values

laptop.explode('Cpu_values', ignore_index=True)

laptop['Weight']=laptop['Weight'].astype(float)

laptop['Ram']=laptop['Ram'].astype(int)

raw_product = input(laptop.Product)
print(raw_product)

print(type(raw_product))

raw_product = input(laptop.Product)
Product= int(raw_product)
print(Product)

print(type(Product))

"""Analiza"""

laptop.info()

"""rozkład zmiennej price_euros"""

sns.displot(laptop.Price_euros)

# sprawdź, ile cali mają monitory
sns.countplot(x='Inches', data=laptop)

# sprawdź, ile Ram mają laptopy
sns.countplot(x='Ram', data=laptop)

# sprawdź rozkład cen domów w zależności od ich kondycji
sns.boxplot(x='Memory', y='Price_euros', data=laptop)

# sprawdź korelację między zmiennymi 
sns.heatmap(laptop.corr(), annot=True)
plt.gcf().set_size_inches(1, 1)

"""korelacja rzedu0,83 pomiędzy wilkością monitora a wagą laptopa oraz miedzy ram a ceną

#Modele predykcyjne
"""

#Zdefiniowanie zmiennej X
X1=laptop[['Ram']]
X2=laptop[['Weight']]
X3=laptop[['Inches']]
X4=laptop[['Cpu_values']]

#Zdefiniowanie zmiennej y
y=laptop['Price_euros']

#Wytrenowanie modelu regresji liniowej 
model1=LinearRegression()
model1.fit(X1,y)

#Przewidywanie wartości y dla zmiennej X
y_predict1=model1.predict(X1)

pd.DataFrame({'actual':y, 'prediction':y_predict1})

r2_score(y, y_predict1)

model2=LinearRegression()
model2.fit(X2,y)

y_predict2=model2.predict(X2)

pd.DataFrame({'actual':y, 'prediction':y_predict2})

r2_score(y, y_predict2)

model3=LinearRegression()
model3.fit(X3,y)

y_predict3=model3.predict(X3)

pd.DataFrame({'actual':y, 'prediction':y_predict3})

r2_score(y, y_predict3)

"""#Regresja liniowa dla X1=[['Ram']]"""

# Podzielenie danych na treningowe i testowe
X_train, X_test, y_train, y_test=train_test_split(X1, y, test_size=0.1, random_state=123)

# Predykcja na zbiorze testowym
y_model1_test=model1.predict(X_test)

# Predykcja na zbiorze treningowym
y_model1_train=model1.predict(X_train)

# obliczanie współczynnika r2
r2_score(y_test, y_model1_test)

# obliczanie metryki MSE
mean_squared_error(y_test, y_model1_test)

# wyświetlenie współczynników dla zmiennych
model1.coef_

# wyświetlenie współczynników dla wyrazu wolnego
model1.intercept_

"""#Model drzewa decyzyjnego"""

# wytrenowanie modelu 
t_model1=DecisionTreeRegressor()
t_model1.fit(X_train, y_train)

# Predykcja na zbiorze testowym
y_t1_test=t_model1.predict(X_test)

# Predykcja na zbiorze treningowym
y_t1_train=t_model1.predict(X_train)

# obliczanie współczynnika r2
r2_score(y_test, y_t1_test)

# obliczanie metryki MSE
mean_squared_error(y_test, y_t1_test)

# Model drzewa
fig, ax=plt.subplots(figsize=(10,12))
ax=tree.plot_tree(t_model1)
plt.show()

"""#Porównanie modeli"""

# bias dla zbioru treningowego dla regresji liniowej
bias_model1_train=mean_absolute_percentage_error(y_train, y_model1_train)
print(bias_model1_train)

# bias dla zbioru testowego dla regresji liniowej
bias_model1_test=mean_absolute_percentage_error(y_test, y_model1_test)
print(bias_model1_test)

#wariancja - model regresji liniowej
variance_model1=bias_model1_test-bias_model1_train
print(variance_model1)

# bias na zbiorze treningowym dla drzewa
bias_t1_train=mean_absolute_percentage_error(y_train, y_t1_train)
print(bias_t1_train)

# bias na zbiorze testowym dla drzewa
bias_t1_test=mean_absolute_percentage_error(y_test, y_t1_test)
print(bias_t1_test)

#wariancja - model drzewa
variance_t1_model=bias_t1_test-bias_t1_train
print(variance_t1_model)

d = {'regresja liniowa': [bias_model1_test, bias_model1_train, variance_model1], 'drzewo': [bias_t1_test, bias_t1_train, variance_t1_model]}
pd.DataFrame(data=d, index=['bias - model testowy', 'bias - model treningowy', 'wariancja'])